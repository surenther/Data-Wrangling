{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65a786c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h2>Milestone 3: Formatting Website Data Source</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955803f",
   "metadata": {},
   "source": [
    "## Data Source and Handling\n",
    "\n",
    "The dataset used in this project was sourced from Wikipedia: [https://en.wikipedia.org/wiki/List_of_countries_by_arable_land_density](https://en.wikipedia.org/wiki/List_of_countries_by_arable_land_density)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39175a62",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc307c1",
   "metadata": {},
   "source": [
    "### 1 - Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58fa5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Ignore all Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede09fd",
   "metadata": {},
   "source": [
    "### 2 - Reading Webdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbb0d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests status Code: 200\n"
     ]
    }
   ],
   "source": [
    "# Make a get requests to Wikipedia using Requests\n",
    "\n",
    "page= requests.get ('https://en.wikipedia.org/wiki/List_of_countries_by_arable_land_density')\n",
    "print (f'Requests status Code:',page.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c45378",
   "metadata": {},
   "source": [
    "### 3 - Identify the Tabular component by count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b96ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tables: 2\n"
     ]
    }
   ],
   "source": [
    "#Read the page from requests response using html parser\n",
    "\n",
    "soup = BeautifulSoup(page.text,'html.parser') \n",
    "\n",
    "tables = soup.findAll(\"table\")  #Scan all the table\n",
    "print (f'Total Tables:',len(tables)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01513d57",
   "metadata": {},
   "source": [
    "### 4 - Identify the right Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b11f327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: \n",
      " No of rows: 221 \n",
      " No of columns: 6\n",
      "Table 2: \n",
      " No of rows: 14 \n",
      " No of columns: 6\n"
     ]
    }
   ],
   "source": [
    "# Find the right table by finding no of rows and columns for each table\n",
    "\n",
    "cntr = 0 \n",
    "num_cols = 0\n",
    "\n",
    "for data in tables:\n",
    "    cntr += 1  #Increment the Counter to display Table index\n",
    "    rows = data.find_all('tr') #Find all the tr to find no of rows\n",
    "    \n",
    "    for row in rows: #To find no of columns loop through each row\n",
    "        cols = row.find_all(['th']) #Find all the header\n",
    "        num_cols = max(num_cols, len(cols)) # Get the max of the count\n",
    "\n",
    "    print (f'Table {cntr}: \\n No of rows: {len(rows)} \\n No of columns: {num_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8af0b7",
   "metadata": {},
   "source": [
    "From the above we can identity that we need to use Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f134b",
   "metadata": {},
   "source": [
    "### 5 - Extract the right Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "904aaf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Location Arable mÂ²/ person Persons /arable km2 %arable Arableland (km2)  \\\n",
      "0       World             1,800                 570     11%       14,000,000   \n",
      "1  Kazakhstan            15,456                  65     11%          296,697   \n",
      "2   Australia            12,062                  83      4%          312,650   \n",
      "3      Canada            10,027                 100      4%          382,590   \n",
      "4   Argentina             9,322                 107     15%          422,088   \n",
      "\n",
      "      Population  \n",
      "0  7,900,000,000  \n",
      "1     19,196,465  \n",
      "2     25,921,089  \n",
      "3     38,155,012  \n",
      "4     45,276,780  \n"
     ]
    }
   ],
   "source": [
    "# Identify table 1\n",
    "target_table = tables[0]  # 0-based index\n",
    "\n",
    "# Extract headers\n",
    "headers = [th.get_text(strip=True) for th in target_table.find_all('tr')[0].find_all('th')]\n",
    "\n",
    "# Extract all rows\n",
    "rows = []\n",
    "for tr in target_table.find_all('tr')[1:]:\n",
    "    cells = tr.find_all(['td', 'th'])\n",
    "    row = [cell.get_text(strip=True) for cell in cells]\n",
    "    if row and len(row) == len(headers):  # Ensure the row matches column count\n",
    "        rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Show preview\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
